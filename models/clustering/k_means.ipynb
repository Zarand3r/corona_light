{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import git\n",
    "import sys\n",
    "import math\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.cluster import _kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = git.Repo(\"./\", search_parent_directories=True)\n",
    "homedir = repo.working_dir\n",
    "datadir = f\"{homedir}\" + \"/models/processing/USA/County_Based/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def logFunc(x):\n",
    "    if x < 0.01:\n",
    "        x = 0.01\n",
    "    return math.log10(x)\n",
    "\n",
    "# Convert longitude latitude pair to x, y, z Cartesian coordinates\\n\n",
    "def convertPts(pair):\n",
    "    lon = pair[0]\n",
    "    lat = pair[1]\n",
    "    R = 3958.8\n",
    "    lonRad = lon * math.pi / 180\n",
    "    latRad = lat * math.pi / 180\n",
    "    x = R * math.cos(latRad) * math.cos(lonRad)\n",
    "    y = R * math.cos(latRad) * math.cos(lonRad)\n",
    "    z = R * math.sin(lat)\n",
    "    return (x, y, z)\n",
    "\n",
    "def getX(x):\n",
    "    return x[0]\n",
    "\n",
    "def getY(x):\n",
    "    return x[1]\n",
    "\n",
    "def getZ(x):\n",
    "    return x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neighbor Data\n",
    "neighborcounties = pd.read_csv(f\"{homedir}/models/processing/USA/County_Based/neighborcounties.csv\", index_col = 0)\n",
    "\n",
    "# read in the files, load as dataframe\n",
    "Age_Race = pd.read_csv(datadir + 'Age_Race_Filled.csv')\n",
    "Population = pd.read_csv(datadir + 'Total_Pop')\n",
    "Density = pd.read_csv(datadir + 'Density.csv')\n",
    "JHU = pd.read_csv(datadir + 'aggregate_jhu_filled.csv')\n",
    "Berkeley = pd.read_csv(datadir + 'Aggregate_Berkeley.csv')\n",
    "Policies = pd.read_csv(datadir + 'Policy_Transit.csv')\n",
    "Geography = pd.read_csv(datadir + 'County_Centers.csv')\n",
    "Health = pd.read_csv(datadir + 'County_Health.csv')\n",
    "Transit = pd.read_csv(datadir + 'Transit.csv')\n",
    "\n",
    "Data = pd.DataFrame()\n",
    "\n",
    "DataBasic = pd.DataFrame()\n",
    "DataDemographics = pd.DataFrame()\n",
    "DataHealth = pd.DataFrame()\n",
    "DataGeography = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['FIPS'] = Geography['fips']\n",
    "\n",
    "# fix population\n",
    "Population.columns = ['fips', 'Population']\n",
    "\n",
    "# drop US territories, train separate models for them\n",
    "FipsSet = []\n",
    "counter = 0\n",
    "for row in Data.iterrows():\n",
    "    row = row[1][0]\n",
    "    if math.floor(row / 1000) > 56:\n",
    "        Data = Data.drop([counter], axis = 0)\n",
    "    else:\n",
    "        FipsSet.append(float(row))\n",
    "    counter += 1\n",
    "    \n",
    "# edit county centers\n",
    "counter1 = 0\n",
    "for row in Geography.iterrows():\n",
    "    if row[1][1] not in FipsSet:\n",
    "        Geography = Geography.drop([counter1], axis = 0)\n",
    "    counter1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nature of the county, includes policies\n",
    "\n",
    "Data['Pop'] = Population['Population']\n",
    "Data['Pop'] = Data['Pop'].div(2000000.0) # population max is 5\n",
    "\n",
    "Data['Density'] = Density['2010 Density per square mile of land area - Population']\n",
    "Data['Density'] = Data['Density'].div(5000.0) # density max is around 14\n",
    "\n",
    "Data['Area'] = Density['Area in square miles - Total area']\n",
    "Data['Area'] = Data['Area'].div(40000.0) #max around 4\n",
    "\n",
    "Data['UrbanRural'] = JHU['Rural-urban_Continuum Code_2013']\n",
    "Data['UrbanRural'] = Data['UrbanRural'].div(1.5) # urban rural max is 7\n",
    "\n",
    "Data['EconType'] = JHU['Economic_typology_2015']\n",
    "Data['EconType'] = Data['EconType'].div(1.5) # economic typology max is 3\n",
    "\n",
    "# Policies\n",
    "Data['Policies'] = Policies['Score']\n",
    "Data['Policies'] = Data['Policies'].div(2) # policies max is just above 4.5\n",
    "\n",
    "# Typical immigration in/out. Proxy for being a sink/source in flows\n",
    "Data['Movement'] = JHU['R_NET_MIG_2018']\n",
    "Data['Movement'] = Data['Movement'].div(20.0) #range around -3.5 to 3.5\n",
    "\n",
    "Data['Transit'] = Transit['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics of the county\n",
    "\n",
    "# Age distribution\n",
    "Data['65+'] = Age_Race['65 to 74 years'] + Age_Race['75 to 84 years'] + Age_Race['85 years and over']\n",
    "Data['65+'] = Data['65+'] / Population['Population']\n",
    "Data['65+'] = Data['65+'].mul(2400) # 65+ max is 4.5\n",
    "\n",
    "# Race/gender\n",
    "Data['Male'] = Berkeley['FracMale2017']\n",
    "Data['Male'] = Data['Male'].mul(6) # male max is 2, generally 1\n",
    "\n",
    "Data['AfricanAmer'] = Age_Race['Exclusively Black or African American'] + Age_Race['Hispanic or Latino (of any race)!!Puerto Rican']\n",
    "Data['AfricanAmer'] = Data['AfricanAmer'] / Population['Population']\n",
    "Data['AfricanAmer'] = Data['AfricanAmer'].mul(4500) # African American max is 6\n",
    "     \n",
    "# Politics/education/income/economy\n",
    "Data['CollegePlus'] = JHU['Percent of adults completing some college or associate\\'s degree 2014-18']\n",
    "Data['CollegePlus'] = Data['CollegePlus'].div(10) # education max is 3, generally around 1-1.5\n",
    "\n",
    "Data['Income'] = JHU['Median_Household_Income_2018']\n",
    "Data['Income'] = Data['Income'].div(40000) # income max is 4, generally around 2  \n",
    "\n",
    "Data['Unemployed'] = JHU['Unemployment_rate_2018']\n",
    "Data['Unemployed'] = Data['Unemployed'].div(3) # unemployed max around 3\n",
    "                         \n",
    "    # need puerto rico voting patterns\n",
    "Data['Dems'] = Berkeley['FracDem']\n",
    "Data['Dems'] = Data['Dems'].mul(7.5) # Dems max is 5, generally around 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Health care of the county\n",
    "\n",
    "Data['Hospitals'] = Berkeley['#Hospitals'] * 10000.0 / Population['Population']\n",
    "Data['Hospitals'] = Data['Hospitals'].div(30.0)\n",
    "\n",
    "Data['HospBeds'] = Health['licensed_beds'] / Population['Population'] # around 2-3\n",
    "\n",
    "Data['ICUBeds'] = Berkeley['#ICU_beds']\n",
    "Data['ICUBeds'] = Data['ICUBeds'] / Population['Population']\n",
    "Data['ICUBeds'] = Data['ICUBeds'].mul(10) # around 11. Outliers ok, very important statistic\n",
    "\n",
    "#note: not considering comorbidities\n",
    "Data['HeartDiseaseMort'] = Berkeley['HeartDiseaseMortality'] \n",
    "Data['HeartDiseaseMort'] = Data['HeartDiseaseMort'].div(60) # max is 10, typically around 3-4\n",
    "\n",
    "Data['StrokeMort'] = Berkeley['StrokeMortality']\n",
    "Data['StrokeMort'] = Data['StrokeMort'].div(10) # max is 7-8, generally around 5\n",
    "\n",
    "Data['Diabetes'] = Berkeley['DiabetesPercentage'] \n",
    "Data['Diabetes'] = Data['Diabetes'].mul(9) # max 3\n",
    "\n",
    "Data['Smokers'] = Berkeley['SmokersPercentage'] \n",
    "Data['Smokers'] = Data['Smokers'].mul(9) # max 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geography\n",
    "\n",
    "Data['pLonLat'] = list(zip(Geography.pclon10, Geography.pclat10)) # population weighted\n",
    "Data['pLonLat'] = Data['pLonLat'].values\n",
    "\n",
    "Data['XYZ'] = Data['pLonLat'].apply(convertPts)\n",
    "\n",
    "Data['xVal'] = Data['XYZ'].apply(getX)\n",
    "Data['xVal'] = Data['xVal'].div(100)\n",
    "\n",
    "Data['yVal'] = Data['XYZ'].apply(getY)\n",
    "Data['yVal'] = Data['yVal'].div(100)\n",
    "\n",
    "Data['zVal'] = Data['XYZ'].apply(getZ)\n",
    "Data['zVal'] = Data['zVal'].div(100)\n",
    "\n",
    "Data = Data.drop(columns=['pLonLat', 'XYZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FIPS', 56045, 0)\n",
      "('Pop', 5.052861, 0)\n",
      "('Density', 13.893679999999998, 0)\n",
      "('Area', 3.6951157500000003, 0)\n",
      "('UrbanRural', 6.0, 53)\n",
      "('EconType', 3.3333333333333335, 53)\n",
      "('Policies', 4.95, 9)\n",
      "('Movement', 3.47, 53)\n",
      "('Transit', 9.9, 4)\n",
      "('65+', 4.007154643627509, 0)\n",
      "('Male', 4.405507745266783, 29)\n",
      "('AfricanAmer', 5.645851501883725, 0)\n",
      "('CollegePlus', 5.7299999999999995, 53)\n",
      "('Income', 3.50955, 53)\n",
      "('Unemployed', 6.033333333333334, 53)\n",
      "('Dems', 7.177139125639056, 29)\n",
      "('Hospitals', 3.875968992248062, 29)\n",
      "('HospBeds', 5.071428571428571, 660)\n",
      "('ICUBeds', 4.945054945054945, 29)\n",
      "('HeartDiseaseMort', 10.05, 29)\n",
      "('StrokeMort', 9.99, 30)\n",
      "('Diabetes', 2.97, 29)\n",
      "('Smokers', 3.734217805860001, 29)\n",
      "('xVal', 10.753779705773864, 0)\n",
      "('yVal', 10.753779705773864, 0)\n",
      "('zVal', 39.587931929159076, 0)\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "for column in Data.columns:\n",
    "    print((column, max(Data[column]), Data[column].isnull().sum()))\n",
    "print(len(Data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        FIPS       Pop  Density      Area  UrbanRural  EconType  Policies  \\\n",
       "0      1001  0.027800  0.01836  0.015110    1.333333  0.000000      0.00   \n",
       "1      1003  0.109011  0.02292  0.050683    2.000000  3.333333      0.15   \n",
       "2      1005  0.012441  0.00620  0.022613    4.000000  2.000000      0.00   \n",
       "3      1007  0.011200  0.00736  0.015654    0.666667  0.000000      0.05   \n",
       "4      1009  0.028920  0.01778  0.016266    0.666667  0.000000      0.00   \n",
       "...     ...       ...      ...       ...         ...       ...       ...   \n",
       "3138  56037       NaN  0.00084  0.262277         NaN       NaN       NaN   \n",
       "3139  56039       NaN  0.00106  0.105408         NaN       NaN       NaN   \n",
       "3140  56041       NaN  0.00202  0.052189         NaN       NaN       NaN   \n",
       "3141  56043       NaN  0.00076  0.056067         NaN       NaN       NaN   \n",
       "3142  56045       NaN  0.00060  0.060000         NaN       NaN       NaN   \n",
       "\n",
       "      Movement  Transit       65+  ...  Hospitals  HospBeds   ICUBeds  \\\n",
       "0         0.03      0.0  0.006603  ...   0.006057  0.001544  0.001090   \n",
       "1         1.24      0.3  0.002579  ...   0.004917  0.002016  0.002508   \n",
       "2        -0.43      0.0  0.014052  ...   0.012722  0.002824  0.001908   \n",
       "3        -0.33      0.1  0.015901  ...   0.014762  0.001550  0.000000   \n",
       "4         0.00      0.0  0.007433  ...   0.005780  0.000694  0.001040   \n",
       "...        ...      ...       ...  ...        ...       ...       ...   \n",
       "3138       NaN      0.0  0.052174  ...        NaN       NaN       NaN   \n",
       "3139       NaN      NaN  0.060358  ...        NaN       NaN       NaN   \n",
       "3140       NaN      NaN  0.021992  ...        NaN       NaN       NaN   \n",
       "3141       NaN      NaN  0.011000  ...        NaN       NaN       NaN   \n",
       "3142       NaN      NaN  0.006985  ...        NaN       NaN       NaN   \n",
       "\n",
       "      HeartDiseaseMort  StrokeMort  Diabetes   Smokers       xVal       yVal  \\\n",
       "0             3.408333        5.61     0.891  1.627340   2.041685   2.041685   \n",
       "1             3.053333        4.19     0.765  1.574013   1.331124   1.331124   \n",
       "2             3.673333        4.90     1.413  1.979999   2.749680   2.749680   \n",
       "3             3.758333        5.72     1.197  1.720278   1.663160   1.663160   \n",
       "4             3.746667        5.28     1.341  1.728780   1.952325   1.952325   \n",
       "...                ...         ...       ...       ...        ...        ...   \n",
       "3138               NaN         NaN       NaN       NaN  -9.785101  -9.785101   \n",
       "3139               NaN         NaN       NaN       NaN -10.190946 -10.190946   \n",
       "3140               NaN         NaN       NaN       NaN -10.550038 -10.550038   \n",
       "3141               NaN         NaN       NaN       NaN  -8.756334  -8.756334   \n",
       "3142               NaN         NaN       NaN       NaN  -7.050470  -7.050470   \n",
       "\n",
       "           zVal  \n",
       "0     34.997863  \n",
       "1    -30.181626  \n",
       "2     16.435023  \n",
       "3     39.549339  \n",
       "4     22.427379  \n",
       "...         ...  \n",
       "3138 -26.680888  \n",
       "3139 -18.565547  \n",
       "3140 -16.544650  \n",
       "3141   1.181323  \n",
       "3142  -2.851157  \n",
       "\n",
       "[3143 rows x 26 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to fill in Data's Nans\n",
    "\n",
    "def fillcol(fips, value,neighborcounties, min_neighbors=2):\n",
    "    #Takes in a column of fips codes, and any type of datafield with some NaNs,\n",
    "    #Computes distance-weighted average of the value across all neighbors of NaN counties\n",
    "    tic1 = time.time()\n",
    "    #Loading in the fips and value into proper dataframes\n",
    "    #This is the df with only nan values\n",
    "    df = pd.DataFrame(data = [fips,value])\n",
    "    df.columns = ['FIPS', 'Values']\n",
    "    df.Values = df.Values.astype(float)\n",
    "    df = df.set_index('FIPS')\n",
    "    \n",
    "    #creating new column to set to the current dataframe values\n",
    "    newcol = []\n",
    "    for ind in df.index:\n",
    "        #for any entries with NaNs\n",
    "        if np.isnan(df['Values'][ind]):\n",
    "            #list of neighbors for NaN county\n",
    "            neighbors = list(neighborcounties[neighborcounties['orgfips'] == ind]['adjfips'])\n",
    "            nonzero = 0\n",
    "            weightedval = 0\n",
    "            totalinvdist = 0\n",
    "            totaldist = 0\n",
    "            vals = 0\n",
    "            #iterates though neighbors of NaN county with non-NaN entires\n",
    "            for n in neighbors:\n",
    "                if n in df.index:\n",
    "                    if ~np.isnan(df['Values'][n]):\n",
    "                        #Getting weighted values, using 1/dist as a scalar to show closer distance counts more\n",
    "                        nonzero += 1\n",
    "                        dist = list(neighborcounties.query('orgfips == ' + str(ind) + ' and adjfips == ' + str(n))['Pop_10'])[0]\n",
    "                        totalinvdist += (1/dist)**1\n",
    "                        weightedval += ((1/dist)**1)*df['Values'][n]\n",
    "            #If there are at least 2 neighbors (this can be adjusted)\n",
    "            if nonzero >= min_neighbors:\n",
    "                newcol.append(weightedval/(totalinvdist))\n",
    "            else:\n",
    "                newcol.append(np.nan)\n",
    "        else:\n",
    "            newcol.append(df['Values'][ind])\n",
    "    toc1 = time.time()\n",
    "    print(toc1 - tic1)\n",
    "    return newcol\n",
    "\n",
    "def fillfixed(colname, data, code, neighborcounties):\n",
    "    #Method to fill up the google mobility data\n",
    "    #Uses colname to designate which column to fill\n",
    "    numnans = len(data[np.isnan(data[colname])])\n",
    "    while numnans > 0:\n",
    "        print(numnans)\n",
    "        tempnum = numnans\n",
    "        #Creating the filled column from method\n",
    "        newcol = fillcol(data[code], data[colname], neighborcounties)\n",
    "        data[colname] = newcol\n",
    "        numnans = len(data[np.isnan(data[colname])])\n",
    "        #Checking if the number of nans changes\n",
    "        if tempnum == numnans:\n",
    "            #if number doesnt change, try again with only 1 neighbor, otherwise quit\n",
    "            newcol = fillcol(data[code], data[colname], neighborcounties)\n",
    "            data[colname] = newcol\n",
    "            numnans = len(data[np.isnan(data[colname])])\n",
    "            if tempnum == numnans:\n",
    "                numnans = 0     \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 3143 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3666527b1fa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfillfixed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FIPS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneighborcounties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-8e25d5f13407>\u001b[0m in \u001b[0;36mfillfixed\u001b[1;34m(colname, data, code, neighborcounties)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mtempnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumnans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m#Creating the filled column from method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mnewcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfillcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneighborcounties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mnumnans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-8e25d5f13407>\u001b[0m in \u001b[0;36mfillcol\u001b[1;34m(fips, value, neighborcounties, min_neighbors)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#This is the df with only nan values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfips\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'FIPS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FIPS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5285\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             raise ValueError(\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 3143 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "# Filling in columns of dataframe by nearest neighbor analysis\n",
    "\n",
    "cols = list(Data.columns)[1:]\n",
    "for col in cols:\n",
    "    Data = fillfixed(col, Data, 'FIPS', neighborcounties)\n",
    "Data = Data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in Data.columns:\n",
    "    print((column, Data[column].isnull().sum()))\n",
    "print(len(Data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting specific dataframes for what we want to cluster\n",
    "\n",
    "DataBasic = Data[['Pop', 'Density', 'Area', 'UrbanRural', 'EconType', 'Policies', 'Movement']]\n",
    "\n",
    "DataDemographics = Data[['Male', 'AfricanAmer', 'CollegePlus', 'Income', 'Unemployed', 'Dems']]\n",
    "\n",
    "DataHealth = Data[['HospBeds', 'ICUBeds', 'HeartDiseaseMort', 'StrokeMort', 'Diabetes', 'Smokers']]\n",
    "\n",
    "# approximate distances between counties\n",
    "# we double count Urban Rural, population, density, size since don't cluster on the entire Data dataframe\n",
    "# so that nearby urban counties are closer than a rural county adjacent from an urban county\n",
    "DataGeography = Data[['Pop', 'Density', 'Area', 'UrbanRural', 'xVal', 'yVal', 'zVal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot k vs error on a graph, decide optimal k via elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the clusters across the country to visualize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
