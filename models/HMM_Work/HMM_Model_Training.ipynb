{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from HMM import unsupervised_HMM\n",
    "from HMM import supervised_HMM\n",
    "from HMM_helper import sample_sentence\n",
    "import simplejson\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import sys\n",
    "repo = git.Repo(\"./\", search_parent_directories=True)\n",
    "homedir = repo.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHMMUnSupData(Input, colname, fipsname):\n",
    "    #Takes input dataframe, and gives out HMM format of data, a list of lists \n",
    "    #of the colname value, each list in the set represents one fips code.\n",
    "    Output = []\n",
    "    for fips in Input[fipsname].unique():\n",
    "        temp = list(Input[Input[fipsname] == fips][colname])\n",
    "        Output.append(temp)\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHMMmap(Output):\n",
    "    #Takes in output of makeHMMUnSupData and transforms data into list from 0 to D-1, where D is the number of unique\n",
    "    #values of the output\n",
    "    #Unqiue values in the input\n",
    "    UniqueVals = np.array(list(set(x for l in Output for x in l)))\n",
    "    UniqueVals = np.sort(UniqueVals)\n",
    "    HMMOutput = []\n",
    "    templs = []\n",
    "    Map = {}\n",
    "    RMap = {}\n",
    "    for x in range(len(UniqueVals)):\n",
    "        Map[int(UniqueVals[x])] = x\n",
    "        RMap[x] = int(UniqueVals[x])\n",
    "    for ls in Output:\n",
    "        for val in ls:\n",
    "            templs.append(Map[val])\n",
    "        HMMOutput.append(templs)\n",
    "        templs = []\n",
    "    return [Map,RMap,HMMOutput]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHMMSupData(UnSupData):\n",
    "    #Takes list of lists of time series data from makeHMMUnSupData and makes it into data with X and Y\n",
    "    X = []\n",
    "    Y = []\n",
    "    tempX = []\n",
    "    tempY = []\n",
    "    for ls in UnSupData:\n",
    "        lenls = len(ls)\n",
    "        for n in range(lenls):            \n",
    "            if n == 0:\n",
    "                tempX.append(ls[n])\n",
    "            elif n == lenls - 1:\n",
    "                tempY.append(ls[n])\n",
    "            else:\n",
    "                tempX.append(ls[n])\n",
    "                tempY.append(ls[n])\n",
    "        if len(tempX) != 0 and len(tempY) != 0:\n",
    "            X.append(tempX)\n",
    "            Y.append(tempY)\n",
    "        tempX = []\n",
    "        tempY = []   \n",
    "    return [X,Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeX(Data, DTW, cluster_col, cluster_num, fipsname, deathsname):\n",
    "    #Takes in the dataset, cluster column and number, and gives out the deaths info in this cluster\n",
    "    #In the form able to be processed by hmmlearn's HMM modules    \n",
    "    fips = list(DTW[DTW[cluster_col] == cluster_num]['FIPS'])\n",
    "    Rows = Data[Data[fipsname].isin(fips)]\n",
    "    RawData = makeHMMUnSupData(Rows, deathsname, fipsname)\n",
    "    #RawData = [a[0] for a in RawData]\n",
    "    temp = []\n",
    "    lengths = []\n",
    "    for i in RawData:\n",
    "        temp.extend(i)\n",
    "        lengths.append(len(i))\n",
    "    temp = np.array(temp).reshape(-1,1)\n",
    "    return [temp, lengths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes of deaths\n",
    "NYT_F = pd.read_csv(f\"{homedir}/models/HMM_Work/NYT_daily_Filled.csv\", index_col=0)\n",
    "NYT_W = pd.read_csv(f\"{homedir}/models/HMM_Work/NYT_daily_Warp.csv\", index_col=0)\n",
    "JHU = pd.read_csv(f\"{homedir}/models/HMM_Work/JHU_daily.csv\", index_col=0)\n",
    "#list of lists of deaths data\n",
    "with open('NYT_daily_Warp_Death.txt') as f:\n",
    "    NYT_daily_Warp_Death = simplejson.load(f)\n",
    "with open('NYT_daily_Death_Filled.txt') as g:\n",
    "    NYT_daily_Death_Filled = simplejson.load(g)\n",
    "with open('JHU_daily_death.txt') as h:\n",
    "    JHU_daily_death = simplejson.load(h)\n",
    "#DTW Based Clusters\n",
    "DTW_Clusters = pd.read_csv(f\"{homedir}/models/HMM_Work/DTW_Clustering.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = makeX(NYT_F, DTW_Clusters, 'NYT_F_Z_L', 3, 'fips', \"deaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = hmm.GaussianHMM(n_components=10, covariance_type=\"full\")\n",
    "model2 = hmm.GMMHMM(n_components=4, n_mix=2, covariance_type=\"full\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83123.19036987724, array([[5.24264714e-026, 0.00000000e+000, 1.00000000e+000,\n",
       "         2.20311290e-122],\n",
       "        [6.71091493e-006, 3.55639168e-041, 9.99993289e-001,\n",
       "         6.30747745e-014],\n",
       "        [6.71165910e-006, 2.29341890e-027, 9.99993288e-001,\n",
       "         6.30984054e-014],\n",
       "        ...,\n",
       "        [6.72395748e-006, 2.05113388e-024, 9.99993276e-001,\n",
       "         6.35857322e-014],\n",
       "        [6.71295138e-006, 2.14389389e-021, 9.99993287e-001,\n",
       "         8.72878937e-013],\n",
       "        [1.82700768e-005, 4.87354010e-016, 9.99981703e-001,\n",
       "         2.65802220e-008]]))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = hmm.GaussianHMM(n_components=4, covariance_type=\"full\")\n",
    "model3.fit(test[0],test[1])\n",
    "model3.score_samples(test[0],test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.78641935e-01, 6.18624625e-04, 9.69925956e-04, 7.66309930e-02,\n",
       "       1.05320001e-01, 1.37472145e-04, 9.37721758e-02, 3.78499830e-02,\n",
       "       5.85895509e-03, 1.99934441e-04])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_stationary_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86155.42524077903,\n",
       " array([[1.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "         1.89160770e-075, 2.52088085e-150, 0.00000000e+000],\n",
       "        [9.99998342e-001, 0.00000000e+000, 1.05986938e-096, ...,\n",
       "         6.70495089e-011, 2.50462540e-013, 3.81110875e-191],\n",
       "        [9.99998342e-001, 1.87126218e-207, 5.57076813e-044, ...,\n",
       "         6.70503660e-011, 2.50462938e-013, 4.81402682e-090],\n",
       "        ...,\n",
       "        [9.99998342e-001, 1.00671306e-208, 2.99697207e-045, ...,\n",
       "         6.70497865e-011, 2.50458637e-013, 2.58985899e-091],\n",
       "        [9.99998342e-001, 7.69135330e-204, 1.89435887e-040, ...,\n",
       "         6.70882422e-011, 2.53815694e-013, 1.63702638e-086],\n",
       "        [9.99995633e-001, 1.55723701e-148, 3.61358648e-034, ...,\n",
       "         4.15376246e-009, 8.51721169e-010, 1.33562472e-080]]))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.score_samples(test[0],test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "            covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "            min_covar=0.001, n_components=2, n_iter=10, params='stmc',\n",
       "            random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "            transmat_prior=1.0, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = [0.5, 1.0, -1.0, 0.42, 0.24]\n",
    "X2 = [2.4, 4.2, 0.5, -0.24]\n",
    "X = np.concatenate([X1, X2]).reshape(-1,1)\n",
    "lengths = [len(X1), len(X2)]\n",
    "hmm.GaussianHMM(n_components=2).fit(X, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5 ],\n",
       "       [ 1.  ],\n",
       "       [-1.  ],\n",
       "       [ 0.42],\n",
       "       [ 0.24],\n",
       "       [ 2.4 ],\n",
       "       [ 4.2 ],\n",
       "       [ 0.5 ],\n",
       "       [-0.24]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is just a testing file so far, because our actual HMM clusterings are not available\n",
    "#Maknig basic list of list data from the direct NYT Data (no clustering we just take the whole dataset)\n",
    "DailyDeathUnSup = makeHMMUnSupData(NYT_daily, 'deaths', 'fips')\n",
    "#Making the mapping of number of deaths to HMM states\n",
    "[DailyDeathMap, DailyDeathRMap, DailyDeathUnSupHMM] = makeHMMmap(DailyDeathUnSup)\n",
    "#Making supervised X and Y datasets\n",
    "DailyDeathSup = makeHMMSupData(DailyDeathUnSupHMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HMM.HiddenMarkovModel at 0x1a01ee52c50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the superviesed testing data, and making a supervised HMM from this \n",
    "SupHMM = supervised_HMM(DailyDeathSup[0],DailyDeathSup[1])\n",
    "SupHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.355 1.145 1.213 1.019 0.806 0.712 0.668 0.776 0.617 0.632 0.631 0.596\n",
      " 0.632 0.562]\n"
     ]
    }
   ],
   "source": [
    "test = np.zeros(14)\n",
    "for j in range(1000): #This generates a sample of length 14, with a starting state of 2, \n",
    "    test += np.array(sample_sentence(SupHMM, DailyDeathMap, 14, 2))#state of 2 means 2 people died in the county yesterday\n",
    "print(test/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
