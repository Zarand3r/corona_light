{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import simplejson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import sys\n",
    "repo = git.Repo(\"./\", search_parent_directories=True)\n",
    "homedir = repo.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHMMUnSupData(Input, colname, fipsname):\n",
    "    #Takes input dataframe, and gives out HMM format of Input data, a list of lists \n",
    "    #of the colname value, each list in the set represents one fips code.\n",
    "    Output = []\n",
    "    for fips in Input[fipsname].unique():\n",
    "        temp = list(Input[Input[fipsname] == fips][colname])\n",
    "        Output.append(temp)\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumulative Death Data\n",
    "NYT_tot = pd.read_csv(f\"{homedir}/data/us/covid/nyt_us_counties.csv\")\n",
    "NYT_tot = NYT_tot.drop(columns=['county','state']).sort_values(['fips','date']).reset_index(drop=True)\n",
    "NYT_tot = NYT_tot.dropna(subset=['fips'])\n",
    "NYT_tot['fips'] = NYT_tot.fips.astype(int)\n",
    "NYT_tot['date'] = pd.to_datetime(NYT_tot['date'])\n",
    "NYT_tot['id'] = NYT_tot.fips.astype(str).str.cat(NYT_tot.date.astype(str), sep=', ')\n",
    "#Making new parameter for deathrate\n",
    "NYT_tot['deathrate'] = NYT_tot['deaths']/NYT_tot['cases']\n",
    "NYT_tot = NYT_tot.fillna(0)\n",
    "#multiplying death rate by 1000 to give integer state values\n",
    "NYT_tot['deathstate'] = NYT_tot['deathrate']*1000\n",
    "NYT_tot['deathstate'] = NYT_tot['deathstate'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Differenced Daily Death Data\n",
    "NYT_daily = pd.read_csv(f\"{homedir}/data/us/covid/nyt_us_counties_daily.csv\")\n",
    "NYT_daily = NYT_daily.drop(columns=['county','state']).sort_values(['fips','date']).reset_index(drop=True)\n",
    "NYT_daily['fips'] = NYT_daily.fips.astype(int)\n",
    "NYT_daily['date'] = pd.to_datetime(NYT_daily['date'])\n",
    "NYT_daily['id'] = NYT_daily.fips.astype(str).str.cat(NYT_daily.date.astype(str), sep=', ')\n",
    "FirstDay = min(NYT_daily.date.unique())\n",
    "LastDay = max(NYT_daily.date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a time-warping of NYT daily data, so each county has a value at the starting day of 2020-01-21\n",
    "# and then a final value at the most recent day\n",
    "NYT_daily_Warp = NYT_daily\n",
    "for fips in NYT_daily.fips.unique():\n",
    "    rows = NYT_daily[NYT_daily['fips'] == fips]\n",
    "    #adding in the first day values\n",
    "    if FirstDay not in rows.date.unique():\n",
    "        NYT_daily_Warp = NYT_daily_Warp.append({'fips': fips, 'date': pd.to_datetime('2020-01-21'), \\\n",
    "                               'cases': 0, 'deaths' : 0, 'id' : str(fips) + ', 2020-01-21'}, ignore_index=True)\n",
    "    #making sure each entry has the final day values\n",
    "    if LastDay not in rows.date.unique():\n",
    "        NYT_daily_Warp = NYT_daily_Warp[NYT_daily_Warp['fips'] != fips]\n",
    "NYT_daily_Warp = NYT_daily_Warp.sort_values(['fips','date']).reset_index(drop=True)\n",
    "NYT_daily_Warp.to_csv('NYT_daily_Warp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_daily_Warp_Death = makeHMMUnSupData(NYT_daily_Warp, 'deaths', 'fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a list of all the counties and dates\n",
    "County_List = list(NYT_daily.fips.unique())\n",
    "Date_List = list(NYT_daily.date.unique())\n",
    "#This creates a base dataframe that contains all pairs of FIPS codes with the valid dates given in Air_Qual\n",
    "CL, DL = pd.core.reshape.util.cartesian_product([County_List, Date_List])\n",
    "BaseFrame = pd.DataFrame(dict(fips=CL, date=DL)).sort_values(['fips','date']).reset_index(drop=True)\n",
    "BaseFrame['id'] = BaseFrame.fips.astype(str).str.cat(BaseFrame.date.astype(str), sep=', ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making frame of all deaths at all dates to properly do DTW clustering\n",
    "NYT_daily_Filled = BaseFrame.join(NYT_daily.set_index('id'), on='id', how='outer', lsuffix='',rsuffix='_x').sort_values(['fips', 'date']).drop(columns=['fips_x','date_x']).fillna(0).drop_duplicates(subset=['fips','date']).reset_index(drop=True)\n",
    "NYT_daily_Filled.to_csv('NYT_daily_Filled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of lists of daily death count for each county, starting 1/23/20, ending most recent date.\n",
    "NYT_daily_Death_Filled = makeHMMUnSupData(NYT_daily_Filled, 'deaths', 'fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JHU Data\n",
    "JHU_tot = pd.read_csv(f\"{homedir}/data/us/covid/JHU_daily_US.csv\").sort_values(['FIPS','Date'])\n",
    "FIPSlist = JHU_tot.FIPS.unique()\n",
    "Datelist = JHU_tot.Date.unique()\n",
    "Datepair = [Datelist[0],Datelist[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting rid of unneded fips code in the list of total codes\n",
    "for fips in FIPSlist:\n",
    "    rows = JHU_tot[JHU_tot['FIPS'] == fips]\n",
    "    datelist = rows.Date.unique()\n",
    "    datepair = [datelist[0],datelist[-1]]\n",
    "    if np.array_equal(Datepair,datepair) != True:\n",
    "        JHU_tot = JHU_tot.drop(list(JHU_tot[JHU_tot['FIPS'] == fips].index))\n",
    "JHU_tot = JHU_tot.sort_values(['FIPS','Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monotonicCol(Data, colname):\n",
    "    #Takes a column that should have monotonically increasing data for a column (number of deaths)\n",
    "    #and adjusts the column to ensure this property, iterating backwards through each fips code's entries\n",
    "    ls = []\n",
    "    tempvals = []\n",
    "    for fips in Data.FIPS.unique():\n",
    "        vals = list(Data[Data['FIPS'] == fips][colname])\n",
    "        flag = True\n",
    "        for val in reversed(vals):\n",
    "            if flag:\n",
    "                flag = False\n",
    "                maxval = val\n",
    "                tempvals.append(maxval)\n",
    "            else:\n",
    "                if val > maxval:\n",
    "                    tempvals.append(maxval)\n",
    "                else:\n",
    "                    maxval = val\n",
    "                    tempvals.append(val)\n",
    "        ls.extend(reversed(tempvals))\n",
    "        tempvals = []\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'FIPS': JHU_tot['FIPS'], 'Date' : JHU_tot['Date'], 'Confirmed' : monotonicCol(JHU_tot,'Confirmed'),\\\n",
    "       'Deaths' : monotonicCol(JHU_tot,'Deaths'),'Active' : monotonicCol(JHU_tot,'Active'), \\\n",
    "        'Recovered' : monotonicCol(JHU_tot,'Recovered')}\n",
    "#Monotonically increaasing transformation of JHU_tot\n",
    "JHU_mono = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumtoDaily(Data, colname):\n",
    "    #Takes cumulative column data and turns the data into daily changes \n",
    "    ls = []\n",
    "    column = Data[colname]\n",
    "    for fips in Data.FIPS.unique():\n",
    "        ls.extend(list(Data[Data['FIPS'] == fips][colname].diff().fillna(0)))\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'FIPS': JHU_mono['FIPS'], 'Date' : JHU_mono['Date'], 'Confirmed' : cumtoDaily(JHU_mono,'Confirmed'),\\\n",
    "       'Deaths' : cumtoDaily(JHU_mono,'Deaths'),'Active' : cumtoDaily(JHU_mono,'Active'), \\\n",
    "        'Recovered' : cumtoDaily(JHU_mono,'Recovered')}\n",
    "#Daily changing data based on monotonically transformed data\n",
    "JHU_daily = pd.DataFrame(data=d)\n",
    "JHU_daily.to_csv('JHU_Daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of lists of daily death count for each county, starting 3/23/20, ending most recent date.\n",
    "JHU_daily_death = makeHMMUnSupData(JHU_daily, 'Deaths', 'FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2892\n",
      "49.386929460580916\n",
      "29.13969571230982\n",
      "0.4276530998996236\n",
      "2892\n",
      "114.0\n",
      "29.13969571230982\n",
      "0.25561136589745453\n",
      "2899\n",
      "48.93135563987582\n",
      "28.45946878233874\n",
      "0.5476759860992931\n"
     ]
    }
   ],
   "source": [
    "#Our three types of death lists for DTW clusterings\n",
    "NYT_daily_Warp_Death\n",
    "NYT_daily_Death_Filled\n",
    "JHU_daily_death\n",
    "\n",
    "print(len(NYT_daily_Warp_Death))\n",
    "print(np.mean([len(a) for a in NYT_daily_Warp_Death]))\n",
    "print(np.mean([sum(a) for a in NYT_daily_Warp_Death]))\n",
    "print(np.mean([np.mean(a) for a in NYT_daily_Warp_Death]))\n",
    "\n",
    "print(len(NYT_daily_Death_Filled))\n",
    "print(np.mean([len(a) for a in NYT_daily_Death_Filled]))\n",
    "print(np.mean([sum(a) for a in NYT_daily_Death_Filled]))\n",
    "print(np.mean([np.mean(a) for a in NYT_daily_Death_Filled]))\n",
    "\n",
    "print(len(JHU_daily_death))\n",
    "print(np.mean([len(a) for a in JHU_daily_death]))\n",
    "print(np.mean([sum(a) for a in JHU_daily_death]))\n",
    "print(np.mean([np.mean(a) for a in JHU_daily_death]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the death data filesw\n",
    "f = open('NYT_daily_Warp_Death.txt', 'w')\n",
    "simplejson.dump(NYT_daily_Warp_Death, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open('NYT_daily_Death_Filled.txt', 'w')\n",
    "simplejson.dump(NYT_daily_Death_Filled, g)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = open('JHU_daily_death.txt', 'w')\n",
    "simplejson.dump(JHU_daily_death, h)\n",
    "h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
